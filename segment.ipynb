{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XRxHiKdGHiT"
      },
      "source": [
        "# Brain tumour image segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4TX-CXBHW4c"
      },
      "source": [
        "## The imaging dataset\n",
        "\n",
        "The dataset is curated from the brain imaging dataset in [Medical Decathlon Challenge](http://medicaldecathlon.com/). To save storage and reduce computational cost, 2D image slices from T1-Gd contrast enhanced 3D brain volumes are extracted and downsampled.\n",
        "\n",
        "The dataset consists of a training set and a test set. Each image is of dimension 120 x 120, with a corresponding label map of the same dimension. There are four number of classes in the label map:\n",
        "\n",
        "- 0: background\n",
        "- 1: edema\n",
        "- 2: non-enhancing tumour\n",
        "- 3: enhancing tumour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook initialisation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq1KWmR3HWYV"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import tarfile\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "\n",
        "datafile = tarfile.open('BrainTumour_2D.tar.gz')\n",
        "datafile.extractall()\n",
        "datafile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_BTL0x6o5a"
      },
      "source": [
        "### Visualising a random set of 4 training images along with their label maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3fgubCRC6m4k",
        "outputId": "d7c80f25-1978-4343-a1f3-24776846bf06"
      },
      "outputs": [],
      "source": [
        "seg_cmap = colors.ListedColormap(['black', 'green', 'blue', 'red'])\n",
        "train_im_dir = 'BrainTumour_2D/training_images/'\n",
        "train_seg_dir = 'BrainTumour_2D/training_labels/'\n",
        "images = os.listdir(train_im_dir)\n",
        "for _ in range(4):\n",
        "  c = random.choice(images)\n",
        "  image = train_im_dir + c\n",
        "  smap = train_seg_dir + c\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
        "  axes[0].imshow(imageio.imread(image), cmap='gray')\n",
        "  axes[0].set_title('Brain MR Image')\n",
        "  axes[1].imshow(imageio.imread(smap), cmap=seg_cmap)\n",
        "  axes[1].set_title('Brain MR Segmentation Map')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xWGT3KaML-D"
      },
      "source": [
        "### Implementing a dataset class to read the imaging dataset and get items, pairs of images and label maps, as training batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p6wFZ3na5z9"
      },
      "outputs": [],
      "source": [
        "def normalise_intensity(image, thres_roi=1.0):\n",
        "    \"\"\" Normalise the image intensity by the mean and standard deviation \"\"\"\n",
        "    # ROI defines the image foreground\n",
        "    val_l = np.percentile(image, thres_roi)\n",
        "    roi = (image >= val_l)\n",
        "    mu, sigma = np.mean(image[roi]), np.std(image[roi])\n",
        "    eps = 1e-6\n",
        "    image2 = (image - mu) / (sigma + eps)\n",
        "    return image2\n",
        "\n",
        "\n",
        "class BrainImageSet(Dataset):\n",
        "    \"\"\" Brain image set \"\"\"\n",
        "    def __init__(self, image_path, label_path='', deploy=False):\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.deploy = deploy\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        image_names = sorted(os.listdir(image_path))\n",
        "        for image_name in image_names:\n",
        "            # Read the image\n",
        "            image = imageio.imread(os.path.join(image_path, image_name))\n",
        "            self.images += [image]\n",
        "\n",
        "            # Read the label map\n",
        "            if not self.deploy:\n",
        "                label_name = os.path.join(label_path, image_name)\n",
        "                label = imageio.imread(label_name)\n",
        "                self.labels += [label]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get an image and perform intensity normalisation\n",
        "        # Dimension: XY\n",
        "        image = normalise_intensity(self.images[idx])\n",
        "\n",
        "        # Get its label map\n",
        "        # Dimension: XY\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "    def get_random_batch(self, batch_size):\n",
        "        # Get a batch of paired images and label maps\n",
        "        # Dimension of images: NCXY\n",
        "        # Dimension of labels: NXY\n",
        "        images, labels = [], []\n",
        "        for _ in range(batch_size):\n",
        "          n = random.randint(0,len(self.images)-1)\n",
        "          images.append(np.stack((self.images[n],), axis=0))\n",
        "          labels.append(self.labels[n])\n",
        "\n",
        "        images = np.array(images)\n",
        "        labels = np.array(labels)\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa4ZpawDNmwu"
      },
      "source": [
        "### Applying the [U-Net architecture](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) for building the segmentation class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMPmBZVGb1aI"
      },
      "outputs": [],
      "source": [
        "\"\"\" U-net \"\"\"\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channel=1, output_channel=1, num_filter=16):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # BatchNorm: by default during training this layer keeps running estimates\n",
        "        # of its computed mean and variance, which are then used for normalization\n",
        "        # during evaluation.\n",
        "\n",
        "        # Encoder path\n",
        "        n = num_filter  # 16\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channel, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 32\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 64\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n *= 2  # 128\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(int(n / 2), n, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n, n, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(n),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Decoder path\n",
        "        self.up3 = nn.ConvTranspose2d(n, int(n / 2), kernel_size=2, stride=2)\n",
        "        self.upconv3 = nn.Sequential(\n",
        "            nn.Conv2d(n, int(n / 2), kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(int(n / 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(int(n / 2), int(n / 2), kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(int(n / 2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n //= 2\n",
        "        self.up2 = nn.ConvTranspose2d(n, int(n / 2), kernel_size=2, stride=2)\n",
        "        self.upconv2 = nn.Sequential(\n",
        "            nn.Conv2d(n, int(n / 2), kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(int(n / 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(int(n / 2), int(n / 2), kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(int(n / 2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        n //= 2\n",
        "        self.up1 = nn.ConvTranspose2d(n, int(n / 2), kernel_size=2, stride=2)\n",
        "        self.upconv1 = nn.Sequential(\n",
        "            nn.Conv2d(n, int(n / 2), kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(int(n / 2)),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(int(n / 2), int(n / 2), kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(int(n / 2)),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        conv1_skip = x\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        conv2_skip = x\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        conv3_skip = x\n",
        "\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        x = self.up3(x)\n",
        "        x = torch.cat((x, conv3_skip), dim=1)\n",
        "        x = self.upconv3(x)\n",
        "\n",
        "        x = self.up2(x)\n",
        "        x = torch.cat((x, conv2_skip), dim=1)\n",
        "        x = self.upconv2(x)\n",
        "\n",
        "        x = self.up1(x)\n",
        "        x = torch.cat((x, conv1_skip), dim=1)\n",
        "        x = self.upconv1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcNWZS08d47P"
      },
      "source": [
        "### Training the segmentation model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaGGkKQndIaR",
        "outputId": "98c47188-4265-48c9-df71-a1fa4d71675a"
      },
      "outputs": [],
      "source": [
        "# CUDA device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device: {0}'.format(device))\n",
        "\n",
        "# Build the model\n",
        "num_class = 4\n",
        "model = UNet(input_channel=1, output_channel=num_class, num_filter=16)\n",
        "model = model.to(device)\n",
        "params = list(model.parameters())\n",
        "\n",
        "model_dir = 'saved_models'\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(params, lr=1e-3)\n",
        "\n",
        "# Segmentation loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Datasets\n",
        "train_set = BrainImageSet('BrainTumour_2D/training_images', 'BrainTumour_2D/training_labels')\n",
        "test_set = BrainImageSet('BrainTumour_2D/test_images', 'BrainTumour_2D/test_labels')\n",
        "\n",
        "# Train the model\n",
        "num_iter = 10000\n",
        "train_batch_size = 16\n",
        "eval_batch_size = 16\n",
        "start = time.time()\n",
        "for it in range(1, 1 + num_iter):\n",
        "    start_iter = time.time()\n",
        "    model.train()\n",
        "\n",
        "    # Get a batch of images and labels\n",
        "    images, labels = train_set.get_random_batch(train_batch_size)\n",
        "    images, labels = torch.from_numpy(images), torch.from_numpy(labels)\n",
        "    images, labels = images.to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)\n",
        "    logits = model(images)\n",
        "\n",
        "    # Perform optimisation and print out the training loss\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Iteration: [{it}/{num_iter}] - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    if it % 100 == 0:\n",
        "        model.eval()\n",
        "        # Disabling gradient calculation during reference to reduce memory consumption\n",
        "        with torch.no_grad():\n",
        "            test_images, test_labels = test_set.get_random_batch(eval_batch_size)\n",
        "            test_images, test_labels = torch.from_numpy(test_images), torch.from_numpy(test_labels)\n",
        "            test_images, test_labels = test_images.to(device, dtype=torch.float32), test_labels.to(device, dtype=torch.long)\n",
        "            test_logits = model(test_images)\n",
        "            test_loss = criterion(test_logits, test_labels).item()\n",
        "            print(f\"Iteration [{it}/{num_iter}] - Test Loss: {test_loss:.4f} - Evaluated on {eval_batch_size} random test images\")\n",
        "\n",
        "    # Save the model\n",
        "    if it % 5000 == 0:\n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, 'model_{0}.pt'.format(it)))\n",
        "print('Training took {:.3f}s in total.'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89yjxjGyb6yT"
      },
      "source": [
        "### Applying the trained model to a random set of 4 test images and visualising the automated segmentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wZeLE0qZjd2j",
        "outputId": "293da45c-3a0c-4bf1-edd8-f8cc10357cd2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(4, 3, figsize=(12, 12))\n",
        "images_test, labels_test = test_set.get_random_batch(4)\n",
        "images_test, labels_test = torch.from_numpy(images_test), torch.from_numpy(labels_test)\n",
        "images_test, labels_test = images_test.to(device, dtype=torch.float32), labels_test.to(device, dtype=torch.long)\n",
        "with torch.no_grad():\n",
        "  model.cuda()\n",
        "  y_hat = model(images_test)\n",
        "for i in range(len(images_test)):\n",
        "    test_image = images_test[i].cpu().squeeze()\n",
        "    ground_truth = labels_test[i].cpu().squeeze()\n",
        "    _, prediction = torch.max(y_hat[i].data, 0)\n",
        "    axes[i, 0].imshow(test_image, cmap='gray')\n",
        "    axes[i, 0].set_title('Test Image')\n",
        "    axes[i, 1].imshow(prediction.cpu(), cmap=seg_cmap)\n",
        "    axes[i, 1].set_title('Automated Segmentation')\n",
        "    axes[i, 2].imshow(ground_truth, cmap=seg_cmap)\n",
        "    axes[i, 2].set_title('Ground Truth Segmentation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj3Qusin_s_r"
      },
      "source": [
        "## Evaluation:\n",
        "\n",
        "The model works fairly well with a final training loss of ~0.0788 and a final test loss of ~0.1236 after 10000 iterations.\n",
        "\n",
        "The model upon general inspection seems to do pretty well overall in detecting conditions.\n",
        "It is fairly good in determining if an edema is present in the scan, however there are times where the model seems to struggle a little with identifying enhancing tumours and may confuse them with non-enhancing tumours."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
